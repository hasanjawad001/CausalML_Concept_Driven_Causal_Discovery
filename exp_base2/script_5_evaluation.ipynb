{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            print('Null rejected: more confident that mean(M1) < mean(M2)')\n",
    "            return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            print('Null rejected: more confident that mean(M1) > mean(M2)')\n",
    "            return 1-pvalue\n",
    "        return True\n",
    "    else:\n",
    "        print('Cannot reject null: no confidence which one is better')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "list_n = [200, 1000] ## [200, 1000]\n",
    "list_d = [10] ## [10, 20]\n",
    "list_s0_factor = [1, 4] ## [1, 4]\n",
    "list_gt = ['ER', 'SF'] ## ['ER', 'SF']\n",
    "list_should_std = [False, True] ## [False, True]\n",
    "n_trials = 50 ## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result = {}\n",
    "\n",
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        with open('datasets/d_result_' + str(n) + '_' + str(d) + '_' + str(s0_factor) + '_' + str(gt) + '_' + str(should_std) + '.pickle', 'rb') as handle:\n",
    "                            d_result_local = pickle.load(handle)\n",
    "                            d_result.update(d_result_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10, 1, 'ER', False) ==> 0.20 ± 0.13 vs 0.15 ± 0.14\n",
      "tstat =  1.3410574461976912\n",
      "pvalue =  0.1848833425162735\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 10, 1, 'ER', False) ==> 40.68 ± 2.63 vs 40.25 ± 2.09\n",
      "tstat =  0.7121588323785594\n",
      "pvalue =  0.47926063922042006\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 10, 1, 'ER', False) ==> 41.81 ± 2.58 vs 40.44 ± 3.33\n",
      "(200, 10, 1, 'ER', False) 31 32\n",
      "\n",
      "\n",
      "(200, 10, 1, 'ER', True) ==> 0.51 ± 0.20 vs 0.54 ± 0.17\n",
      "tstat =  -0.8304051203122653\n",
      "pvalue =  0.40872911811601076\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 10, 1, 'ER', True) ==> 33.58 ± 4.01 vs 30.38 ± 5.24\n",
      "tstat =  3.1555604473437784\n",
      "pvalue =  0.0022879833671881605\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 10, 1, 'ER', True) ==> 35.63 ± 4.51 vs 33.74 ± 5.87\n",
      "(200, 10, 1, 'ER', True) 43 42\n",
      "\n",
      "\n",
      "(200, 10, 1, 'SF', False) ==> 0.10 ± 0.09 vs 0.06 ± 0.11\n",
      "tstat =  1.7299630161323445\n",
      "pvalue =  0.08912674494086956\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 10, 1, 'SF', False) ==> 37.87 ± 4.28 vs 42.17 ± 1.71\n",
      "tstat =  -5.177131018289835\n",
      "pvalue =  6.867453807295543e-06\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 10, 1, 'SF', False) ==> 37.65 ± 4.50 vs 40.87 ± 1.65\n",
      "(200, 10, 1, 'SF', False) 31 30\n",
      "\n",
      "\n",
      "(200, 10, 1, 'SF', True) ==> 0.26 ± 0.15 vs 0.13 ± 0.13\n",
      "tstat =  3.8332622022339793\n",
      "pvalue =  0.00027698255902735376\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 10, 1, 'SF', True) ==> 37.94 ± 3.25 vs 32.98 ± 5.02\n",
      "tstat =  5.299099359935526\n",
      "pvalue =  1.1945076700319603e-06\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 10, 1, 'SF', True) ==> 37.17 ± 4.18 vs 30.98 ± 5.51\n",
      "(200, 10, 1, 'SF', True) 36 43\n",
      "\n",
      "\n",
      "(200, 10, 4, 'ER', False) ==> 0.41 ± 0.14 vs 0.30 ± 0.13\n",
      "tstat =  3.640200118268132\n",
      "pvalue =  0.000517946189548814\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 10, 4, 'ER', False) ==> 28.27 ± 5.50 vs 32.06 ± 5.00\n",
      "tstat =  -3.060526810902071\n",
      "pvalue =  0.003133362990351955\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 10, 4, 'ER', False) ==> 41.05 ± 2.14 vs 34.71 ± 3.08\n",
      "(200, 10, 4, 'ER', False) 37 35\n",
      "\n",
      "\n",
      "(200, 10, 4, 'ER', True) ==> 0.60 ± 0.11 vs 0.55 ± 0.11\n",
      "tstat =  2.0236876012298564\n",
      "pvalue =  0.04591223795329415\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 10, 4, 'ER', True) ==> 20.20 ± 4.61 vs 21.54 ± 4.63\n",
      "tstat =  -1.4125771052807905\n",
      "pvalue =  0.16115920490038665\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 10, 4, 'ER', True) ==> 37.48 ± 3.83 vs 36.12 ± 3.63\n",
      "(200, 10, 4, 'ER', True) 46 48\n",
      "\n",
      "\n",
      "(200, 10, 4, 'SF', False) ==> 0.20 ± 0.14 vs 0.17 ± 0.11\n",
      "tstat =  0.8446165337344106\n",
      "pvalue =  0.40146963119156664\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 10, 4, 'SF', False) ==> 37.34 ± 3.43 vs 38.97 ± 3.14\n",
      "tstat =  -2.0421121475347097\n",
      "pvalue =  0.04514317858086828\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 10, 4, 'SF', False) ==> 40.66 ± 2.88 vs 39.24 ± 2.44\n",
      "(200, 10, 4, 'SF', False) 35 33\n",
      "\n",
      "\n",
      "(200, 10, 4, 'SF', True) ==> 0.29 ± 0.15 vs 0.36 ± 0.12\n",
      "tstat =  -2.298473871917039\n",
      "pvalue =  0.024036421730245696\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 10, 4, 'SF', True) ==> 30.09 ± 5.60 vs 26.38 ± 4.65\n",
      "tstat =  3.3654112444520536\n",
      "pvalue =  0.0011546696072067208\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 10, 4, 'SF', True) ==> 25.49 ± 5.87 vs 26.57 ± 6.47\n",
      "(200, 10, 4, 'SF', True) 45 42\n",
      "\n",
      "\n",
      "(1000, 10, 1, 'ER', False) ==> 0.10 ± 0.15 vs 0.12 ± 0.10\n",
      "tstat =  -0.4394601230886989\n",
      "pvalue =  0.6624000099987843\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 10, 1, 'ER', False) ==> 38.86 ± 2.72 vs 35.09 ± 2.53\n",
      "tstat =  5.5646184794317115\n",
      "pvalue =  7.756995689098063e-07\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 10, 1, 'ER', False) ==> 37.18 ± 3.23 vs 33.91 ± 3.46\n",
      "(1000, 10, 1, 'ER', False) 28 33\n",
      "\n",
      "\n",
      "(1000, 10, 1, 'ER', True) ==> 0.41 ± 0.19 vs 0.43 ± 0.16\n",
      "tstat =  -0.6797218745722209\n",
      "pvalue =  0.49834918080799184\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 10, 1, 'ER', True) ==> 17.68 ± 5.70 vs 12.13 ± 3.32\n",
      "tstat =  5.902051643158504\n",
      "pvalue =  8.334514251681106e-08\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 10, 1, 'ER', True) ==> 16.88 ± 6.40 vs 13.34 ± 4.34\n",
      "(1000, 10, 1, 'ER', True) 50 47\n",
      "\n",
      "\n",
      "(1000, 10, 1, 'SF', False) ==> 0.05 ± 0.08 vs 0.03 ± 0.06\n",
      "tstat =  1.1351956791768443\n",
      "pvalue =  0.2615249337865075\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 10, 1, 'SF', False) ==> 38.93 ± 3.81 vs 40.81 ± 1.49\n",
      "tstat =  -2.509089962795596\n",
      "pvalue =  0.01693280613065739\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 10, 1, 'SF', False) ==> 37.17 ± 3.43 vs 38.84 ± 1.62\n",
      "(1000, 10, 1, 'SF', False) 29 37\n",
      "\n",
      "\n",
      "(1000, 10, 1, 'SF', True) ==> 0.12 ± 0.12 vs 0.12 ± 0.16\n",
      "tstat =  0.017294934849756628\n",
      "pvalue =  0.9862403421614785\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 10, 1, 'SF', True) ==> 21.72 ± 6.29 vs 15.67 ± 4.33\n",
      "tstat =  5.4693550494247605\n",
      "pvalue =  4.86958125172028e-07\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 10, 1, 'SF', True) ==> 18.00 ± 6.14 vs 13.94 ± 4.39\n",
      "(1000, 10, 1, 'SF', True) 47 49\n",
      "\n",
      "\n",
      "(1000, 10, 4, 'ER', False) ==> 0.17 ± 0.09 vs 0.14 ± 0.06\n",
      "tstat =  1.8397700994119082\n",
      "pvalue =  0.06954873558742422\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 10, 4, 'ER', False) ==> 36.09 ± 3.21 vs 36.50 ± 2.72\n",
      "tstat =  -0.629986717344683\n",
      "pvalue =  0.5305112669453\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 10, 4, 'ER', False) ==> 23.72 ± 4.32 vs 21.06 ± 3.28\n",
      "(1000, 10, 4, 'ER', False) 46 36\n",
      "\n",
      "\n",
      "(1000, 10, 4, 'ER', True) ==> 0.38 ± 0.10 vs 0.44 ± 0.11\n",
      "tstat =  -2.914384198796065\n",
      "pvalue =  0.00448860845604261\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 10, 4, 'ER', True) ==> 26.65 ± 3.87 vs 24.30 ± 4.46\n",
      "tstat =  2.714812398490042\n",
      "pvalue =  0.00796383157643853\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 10, 4, 'ER', True) ==> 21.33 ± 4.63 vs 28.98 ± 4.70\n",
      "(1000, 10, 4, 'ER', True) 48 46\n",
      "\n",
      "\n",
      "(1000, 10, 4, 'SF', False) ==> 0.09 ± 0.09 vs 0.06 ± 0.05\n",
      "tstat =  2.098133413775778\n",
      "pvalue =  0.04063785525163536\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 10, 4, 'SF', False) ==> 39.54 ± 2.39 vs 40.80 ± 2.14\n",
      "tstat =  -2.402544662652247\n",
      "pvalue =  0.018976605756032005\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 10, 4, 'SF', False) ==> 32.23 ± 3.41 vs 30.54 ± 3.63\n",
      "(1000, 10, 4, 'SF', False) 35 41\n",
      "\n",
      "\n",
      "(1000, 10, 4, 'SF', True) ==> 0.16 ± 0.13 vs 0.29 ± 0.14\n",
      "tstat =  -4.577456082612106\n",
      "pvalue =  1.4931843479657954e-05\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 10, 4, 'SF', True) ==> 26.92 ± 3.47 vs 25.07 ± 5.03\n",
      "tstat =  2.061294426949818\n",
      "pvalue =  0.04263522448862615\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 10, 4, 'SF', True) ==> 9.20 ± 5.86 vs 19.80 ± 4.96\n",
      "(1000, 10, 4, 'SF', True) 49 45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        \n",
    "                        fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'X')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz.append(value[4])\n",
    "                        nvalid = len(tpr)\n",
    "                        assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "                            \n",
    "                        fdr2, tpr2, fpr2, shd2, nnz2 = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'X_fake')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr2.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr2.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr2.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd2.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz2.append(value[4])      \n",
    "                        nvalid2 = len(tpr2)\n",
    "                        assert nvalid2 == len(fdr2) == len(fpr2) == len(shd2) == len(nnz2)\n",
    "                                \n",
    "                          \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr2), np.std(fdr2)))\n",
    "                        # which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr2), np.std(fdr2), nvalid2)                                                \n",
    "                        print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "                        which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr2), np.std(fpr2)))\n",
    "                        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr2), np.std(fpr2), nvalid2)                        \n",
    "                        print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "                        which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "                        print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "                        print(key[:-2], nvalid, nvalid2)\n",
    "                        print()\n",
    "                        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
