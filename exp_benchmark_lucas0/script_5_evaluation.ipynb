{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            s = 'Null rejected: more confident that mean(M1) < mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            s = 'Null rejected: more confident that mean(M1) > mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 1-pvalue\n",
    "        return (tstat, pvalue, '-----------------') ## return True\n",
    "    else:\n",
    "        s = 'Cannot reject null: no confidence which one is better'\n",
    "        print(s)\n",
    "        return (tstat, pvalue, s) ## return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tstat =  -1.1344593276288957\n",
      "pvalue =  0.2614595813000171\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -20.508189808479102\n",
      "pvalue =  8.622263383817548e-33\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "2\n",
      "\n",
      "\n",
      "0 ================= 7.46 23.76\n",
      "           0                       1            2            3        4   \\\n",
      "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)     pval   \n",
      "1        True                  50, 50  0.76 ± 0.14  0.78 ± 0.04  0.26146   \n",
      "\n",
      "         5                                                  6             7   \\\n",
      "0     tstat                                            comment    shd (nCon)   \n",
      "1 -1.134459  Cannot reject null: no confidence which one is...  15.54 ± 2.30   \n",
      "\n",
      "             8     9         10  \\\n",
      "0    shd (nReg)  pval     tstat   \n",
      "1  23.16 ± 1.27   0.0 -20.50819   \n",
      "\n",
      "                                                  11  \n",
      "0                                            comment  \n",
      "1  Null rejected: more confident that mean(M1) < ...  \n",
      "\n",
      "100\n",
      "tstat =  2.085964423158485\n",
      "pvalue =  0.04114531924517267\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -29.30071593718499\n",
      "pvalue =  1.3532730862004803e-46\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "2\n",
      "\n",
      "\n",
      "1 ================= 7.94 25.86\n",
      "           0                       1            2            3         4   \\\n",
      "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)      pval   \n",
      "1        True                  50, 50  0.75 ± 0.13  0.71 ± 0.05  0.041145   \n",
      "\n",
      "         5                                                  6             7   \\\n",
      "0     tstat                                            comment    shd (nCon)   \n",
      "1  2.085964  Null rejected: more confident that mean(M1) > ...  11.14 ± 1.25   \n",
      "\n",
      "             8     9          10  \\\n",
      "0    shd (nReg)  pval      tstat   \n",
      "1  20.36 ± 1.84   0.0 -29.300716   \n",
      "\n",
      "                                                  11  \n",
      "0                                            comment  \n",
      "1  Null rejected: more confident that mean(M1) < ...  \n",
      "\n",
      "100\n",
      "tstat =  -11.461121451909777\n",
      "pvalue =  2.6030672690746003e-19\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -48.36876956325127\n",
      "pvalue =  6.682631288922258e-60\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "2\n",
      "\n",
      "\n",
      "2 ================= 13.8 28.1\n",
      "           0                       1            2            3     4   \\\n",
      "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)  pval   \n",
      "1        True                  50, 50  0.76 ± 0.03  0.82 ± 0.02   0.0   \n",
      "\n",
      "          5                                                  6             7   \\\n",
      "0      tstat                                            comment    shd (nCon)   \n",
      "1 -11.461121  Null rejected: more confident that mean(M1) < ...  12.16 ± 0.78   \n",
      "\n",
      "             8     9         10  \\\n",
      "0    shd (nReg)  pval     tstat   \n",
      "1  22.96 ± 1.37   0.0 -48.36877   \n",
      "\n",
      "                                                  11  \n",
      "0                                            comment  \n",
      "1  Null rejected: more confident that mean(M1) < ...  \n",
      "\n",
      "100\n",
      "tstat =  -2.257426917804291\n",
      "pvalue =  0.028416262194809992\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -50.176291633040464\n",
      "pvalue =  3.013859224221673e-65\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "2\n",
      "\n",
      "\n",
      "3 ================= 1.44 16.28\n",
      "           0                       1            2            3         4   \\\n",
      "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)      pval   \n",
      "1        True                  50, 50  0.72 ± 0.44  0.86 ± 0.03  0.028416   \n",
      "\n",
      "         5                                                  6             7   \\\n",
      "0     tstat                                            comment    shd (nCon)   \n",
      "1 -2.257427  Null rejected: more confident that mean(M1) < ...  13.26 ± 1.11   \n",
      "\n",
      "             8     9          10  \\\n",
      "0    shd (nReg)  pval      tstat   \n",
      "1  22.74 ± 0.74   0.0 -50.176292   \n",
      "\n",
      "                                                  11  \n",
      "0                                            comment  \n",
      "1  Null rejected: more confident that mean(M1) < ...  \n",
      "\n",
      "100\n",
      "tstat =  -0.6605632007207503\n",
      "pvalue =  0.5119345572964704\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -41.382323700450684\n",
      "pvalue =  8.250940427808747e-47\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "2\n",
      "\n",
      "\n",
      "4 ================= 1.04 19.22\n",
      "           0                       1            2            3         4   \\\n",
      "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)      pval   \n",
      "1        True                  50, 50  0.69 ± 0.46  0.73 ± 0.04  0.511935   \n",
      "\n",
      "         5                                                  6             7   \\\n",
      "0     tstat                                            comment    shd (nCon)   \n",
      "1 -0.660563  Cannot reject null: no confidence which one is...  12.02 ± 0.42   \n",
      "\n",
      "             8     9          10  \\\n",
      "0    shd (nReg)  pval      tstat   \n",
      "1  19.24 ± 1.16   0.0 -41.382324   \n",
      "\n",
      "                                                  11  \n",
      "0                                            comment  \n",
      "1  Null rejected: more confident that mean(M1) < ...  \n",
      "\n",
      "100\n",
      "tstat =  -2.825296811340099\n",
      "pvalue =  0.005724460968531244\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -72.27726521863335\n",
      "pvalue =  1.4739501355153445e-72\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "2\n",
      "\n",
      "\n",
      "5 ================= 10.96 26.92\n",
      "           0                       1            2            3         4   \\\n",
      "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)      pval   \n",
      "1        True                  50, 50  0.80 ± 0.03  0.81 ± 0.03  0.005724   \n",
      "\n",
      "         5                                                  6             7   \\\n",
      "0     tstat                                            comment    shd (nCon)   \n",
      "1 -2.825297  Null rejected: more confident that mean(M1) < ...  11.48 ± 0.50   \n",
      "\n",
      "             8     9          10  \\\n",
      "0    shd (nReg)  pval      tstat   \n",
      "1  21.92 ± 0.89   0.0 -72.277265   \n",
      "\n",
      "                                                  11  \n",
      "0                                            comment  \n",
      "1  Null rejected: more confident that mean(M1) < ...  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_should_std = [True] ## [False, True]\n",
    "\n",
    "## experiments\n",
    "list_wl1l2 = [\n",
    "            (0.1, 0.0001, 0.001),\n",
    "            (0.1, 0.0001, 0.002),\n",
    "            (0.1, 0.0001, 0.01),\n",
    "            (0.2, 0.0001, 0.001),\n",
    "            (0.2, 0.0001, 0.002),\n",
    "            (0.2, 0.0001, 0.01),\n",
    "            \n",
    "            \n",
    "            # (0.1, 0.0002, 0.0010),            \n",
    "            # (0.1, 0.0005, 0.0010),\n",
    "            # (0.1, 0.0010, 0.0010),    \n",
    "            # ##\n",
    "            # (0.15, 0.0001, 0.0010),\n",
    "            # (0.15, 0.0002, 0.0010),            \n",
    "            # (0.15, 0.0005, 0.0010),\n",
    "            # (0.15, 0.0010, 0.0010),            \n",
    "            # ##\n",
    "            # (0.1, 0.0001, 0.0001),\n",
    "            # (0.1, 0.0002, 0.0001),            \n",
    "            # (0.1, 0.0005, 0.0001),\n",
    "            # (0.1, 0.0010, 0.0001),            \n",
    "            # ##\n",
    "            # (0.15, 0.0001, 0.0001),\n",
    "            # (0.15, 0.0002, 0.0001),            \n",
    "            # (0.15, 0.0005, 0.0001),\n",
    "            # (0.15, 0.0010, 0.0001),            \n",
    "    \n",
    "]\n",
    "for ix, (w, l1, l2) in enumerate(list_wl1l2):\n",
    "    n_trials = 50 ## 10 or 50\n",
    "\n",
    "    d_result = {}\n",
    "\n",
    "    for should_std in list_should_std:\n",
    "        with open('datasets/d_result_' + str(should_std) + '_' + str(ix) + '.pickle', 'rb') as handle:\n",
    "            d_result_local = pickle.load(handle)\n",
    "            d_result.update(d_result_local)\n",
    "\n",
    "    # d_result ## len := 4800 = 32 * 50 * 3 (nCon, nReg, nRegFlat)\n",
    "    print(len(d_result))\n",
    "\n",
    "    list_row = [\n",
    "        [\n",
    "            'should_std', '# success (nCon, nReg)',\n",
    "            'fdr (nCon)', 'fdr (nReg)', 'pval', 'tstat', 'comment',\n",
    "            'shd (nCon)', 'shd (nReg)', 'pval', 'tstat', 'comment'        \n",
    "        ]\n",
    "    ]\n",
    "    for should_std in list_should_std:    \n",
    "        fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "        for tn in range(n_trials):\n",
    "            key = (should_std, tn, 'nCon')\n",
    "            value = d_result[key]\n",
    "            if value[0] != '-':\n",
    "                fdr.append(value[0])\n",
    "            if value[1] != '-':\n",
    "                tpr.append(value[1])\n",
    "            if value[2] != '-':\n",
    "                fpr.append(value[2])\n",
    "            if value[3] != '-':\n",
    "                shd.append(value[3])\n",
    "            if value[4] != '-':\n",
    "                nnz.append(value[4])\n",
    "        nvalid = len(tpr)\n",
    "        assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "\n",
    "        fdr3, tpr3, fpr3, shd3, nnz3 = [], [], [], [], []\n",
    "        for tn in range(n_trials):\n",
    "            key = (should_std, tn, 'nRegFlat') ## nReg or nRegFlat\n",
    "            value = d_result[key]\n",
    "            if value[0] != '-':\n",
    "                fdr3.append(value[0])\n",
    "            if value[1] != '-':\n",
    "                tpr3.append(value[1])\n",
    "            if value[2] != '-':\n",
    "                fpr3.append(value[2])\n",
    "            if value[3] != '-':\n",
    "                shd3.append(value[3])\n",
    "            if value[4] != '-':\n",
    "                nnz3.append(value[4])      \n",
    "        nvalid3 = len(tpr3)\n",
    "        assert nvalid3 == len(fdr3) == len(fpr3) == len(shd3) == len(nnz3)\n",
    "\n",
    "\n",
    "        # print(n, d, s0_factor, gt, should_std)                        \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr2), np.std(fdr2)))\n",
    "    #     t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr2), np.std(fdr2), nvalid2)                                                \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "        # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr2), np.std(fpr2)))\n",
    "        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr2), np.std(fpr2), nvalid2)                        \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "    #     t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "        # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz2), np.std(nnz2), nvalid2)   \n",
    "        # print(key[:-2], nvalid, nvalid2)\n",
    "        # print()\n",
    "        # print()\n",
    "        # print(n, d, s0_factor, gt, should_std)  \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr3), np.std(fdr3)))\n",
    "        t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr3), np.std(fdr3), nvalid3)                                                                        \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr3), np.std(tpr3)))\n",
    "        # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr3), np.std(tpr3), nvalid3)                        \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr3), np.std(fpr3)))\n",
    "        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr3), np.std(fpr3), nvalid3)                                                \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd3), np.std(shd3)))  \n",
    "        t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd3), np.std(shd3), nvalid3)                    \n",
    "        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz3), np.std(nnz3)))   \n",
    "        # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz3), np.std(nnz3), nvalid3)   \n",
    "        # print(key[:-2], nvalid, nvalid3)\n",
    "        # print()tpr\n",
    "        # print()   \n",
    "\n",
    "        row = [\n",
    "            str(should_std), '{0}, {1}'.format(nvalid, nvalid3),\n",
    "            \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr), np.std(fdr)),\n",
    "            \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr3), np.std(fdr3)),\n",
    "            p1, t1, s1,\n",
    "            \"{:0.2f} ± {:0.2f}\".format(np.mean(shd), np.std(shd)),\n",
    "            \"{:0.2f} ± {:0.2f}\".format(np.mean(shd3), np.std(shd3)),\n",
    "            p2, t2, s2                            \n",
    "        ]\n",
    "        list_row.append(row)                        \n",
    "\n",
    "    print(len(list_row))\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(list_row)\n",
    "    writer = pd.ExcelWriter('datasets/result_1_nCon_nRegFlat_' + str(ix) + '.xlsx', engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name='1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(ix, '=================', np.mean(nnz), np.mean(nnz3))\n",
    "    print(pd.read_excel('datasets/result_1_nCon_nRegFlat_' + str(ix) + '.xlsx').head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
