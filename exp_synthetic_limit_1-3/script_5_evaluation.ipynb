{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            s = 'Null rejected: more confident that mean(M1) < mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            s = 'Null rejected: more confident that mean(M1) > mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 1-pvalue\n",
    "        return (tstat, pvalue, '-----------------') ## return True\n",
    "    else:\n",
    "        s = 'Cannot reject null: no confidence which one is better'\n",
    "        print(s)\n",
    "        return (tstat, pvalue, s) ## return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "list_n = [200, 1000] ## [200, 1000]\n",
    "list_d = [10, 20] ## [10, 20]\n",
    "list_s0_factor = [1, 4] ## [1, 4]\n",
    "list_gt = ['ER', 'SF'] ## ['ER', 'SF']\n",
    "list_should_std = [False, True] ## [False, True]\n",
    "n_trials = 50 ## 10 or 50\n",
    "# list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "# list_n = [200] ## [200, 1000]\n",
    "# list_d = [10] ## [10, 20]\n",
    "# list_s0_factor = [1, 4] ## [1, 4]\n",
    "# list_gt = ['ER'] ## ['ER', 'SF']\n",
    "# list_should_std = [False] ## [False, True]\n",
    "# n_trials = 3 ## 10 or 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result = {}\n",
    "\n",
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        with open('datasets/d_result_' + str(n) + '_' + str(d) + '_' + str(s0_factor) + '_' + str(gt) + '_' + str(should_std) + '.pickle', 'rb') as handle:\n",
    "                            d_result_local = pickle.load(handle)\n",
    "                            d_result.update(d_result_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_result ## len := 4800 = 32 * 50 * 3 (nCon, nReg, nRegFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstat =  2.139897888106929\n",
      "pvalue =  0.035437725567253345\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -14.65982321648635\n",
      "pvalue =  1.4109825640540557e-25\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.5086756986794985\n",
      "pvalue =  0.013963772236659582\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -17.364163720597183\n",
      "pvalue =  2.42453436895732e-29\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.1167987547656082\n",
      "pvalue =  0.26769964787890194\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -14.044275072215068\n",
      "pvalue =  1.392761756251286e-24\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.9923335523041268\n",
      "pvalue =  0.32447683399935157\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -12.987004305443902\n",
      "pvalue =  3.069648828561921e-22\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  1.8820581207806353\n",
      "pvalue =  0.06389536087176907\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -22.090216898439145\n",
      "pvalue =  6.87164744886921e-31\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.143453184448643\n",
      "pvalue =  0.03558146164066438\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -19.225683553031388\n",
      "pvalue =  8.206627146542064e-30\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.8297707537688903\n",
      "pvalue =  0.07131536552554214\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -19.53861264432504\n",
      "pvalue =  4.2340076929780684e-35\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -0.3385458004293301\n",
      "pvalue =  0.7358766402946297\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -16.315881966444643\n",
      "pvalue =  6.216020368801509e-29\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  1.2617035603262567\n",
      "pvalue =  0.21007460726908728\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -10.111712078361109\n",
      "pvalue =  1.1484862681598947e-16\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  1.551402046648019\n",
      "pvalue =  0.1243194259416188\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -11.73685265008498\n",
      "pvalue =  6.414711527905566e-20\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -0.6314605024849631\n",
      "pvalue =  0.5293664080257807\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -8.66309343626015\n",
      "pvalue =  1.0023241955353262e-13\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.8220402144329485\n",
      "pvalue =  0.413250225633207\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -7.751799753979019\n",
      "pvalue =  8.580973744884789e-12\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.9621936387723024\n",
      "pvalue =  0.33903320910335055\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -21.63682302235454\n",
      "pvalue =  3.814092269918822e-36\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.5496524011759276\n",
      "pvalue =  0.013066427204600873\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -22.441564106281604\n",
      "pvalue =  4.1225830773159355e-37\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.491118867756254\n",
      "pvalue =  0.1407595463547036\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -20.77669369536119\n",
      "pvalue =  1.0501882517294917e-36\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.34137105349487845\n",
      "pvalue =  0.7338756189791844\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -14.284908158553053\n",
      "pvalue =  2.752953547674652e-25\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.5344961728182085\n",
      "pvalue =  2.324878881981427e-05\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -17.367615622086838\n",
      "pvalue =  1.4705397160003463e-28\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.7786340656739423\n",
      "pvalue =  0.07906367378852289\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -18.01827167661015\n",
      "pvalue =  6.0325254747789e-32\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.560505079385128\n",
      "pvalue =  2.1057183656996974e-05\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -13.40911060153991\n",
      "pvalue =  2.9196229694745043e-23\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -6.117024547820441\n",
      "pvalue =  2.7554906895194093e-08\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -17.962147801736066\n",
      "pvalue =  1.0496619959848128e-31\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -0.9827295665271404\n",
      "pvalue =  0.3285933748802161\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -17.81290846996543\n",
      "pvalue =  4.920615550788845e-32\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.016874185829837678\n",
      "pvalue =  0.9865762230279741\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -12.98712560899633\n",
      "pvalue =  6.258240317010072e-23\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.896444740126259\n",
      "pvalue =  0.00477746200257431\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -15.766309227045065\n",
      "pvalue =  5.730694824578255e-27\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.518498907630047\n",
      "pvalue =  0.013564169489371001\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -12.317529471233236\n",
      "pvalue =  2.3151709713611513e-21\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.4941320597834322\n",
      "pvalue =  0.13941294432509663\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -8.73183141329655\n",
      "pvalue =  2.725430735516174e-13\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.6743287787261648\n",
      "pvalue =  0.5017031784466903\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -7.189971384107088\n",
      "pvalue =  1.6723268880218952e-10\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.2016596757609235\n",
      "pvalue =  0.030449607814795485\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -3.2186315478935925\n",
      "pvalue =  0.0017582924393606467\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.764478610264679\n",
      "pvalue =  0.007191935533802888\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -5.747230067374019\n",
      "pvalue =  1.0262651644562646e-07\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.2479563772572105\n",
      "pvalue =  0.8047455094508951\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -7.49246659720526\n",
      "pvalue =  3.085168001259594e-11\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.1064487809880634\n",
      "pvalue =  0.037801127913754964\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -7.410243968658807\n",
      "pvalue =  5.1893161627186794e-11\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.63507255283887\n",
      "pvalue =  1.337300661598415e-05\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -13.208320272730202\n",
      "pvalue =  2.401160581519994e-23\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.1714048052639099\n",
      "pvalue =  0.24449178556096046\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -7.861674605764768\n",
      "pvalue =  5.282038332993725e-12\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n"
     ]
    }
   ],
   "source": [
    "list_row = [\n",
    "    [\n",
    "        'dim_con',\n",
    "        'should_std', 'n', 'd', 's0', 'gt',\n",
    "        '# success (nCon, nReg)',\n",
    "        'tpr (nCon)', 'tpr (nReg)', 'pval', 'tstat', 'comment',\n",
    "        'shd (nCon)', 'shd (nReg)', 'pval', 'tstat', 'comment'        \n",
    "    ]\n",
    "]\n",
    "for dt, st in list_dt_st:\n",
    "    for should_std in list_should_std:    \n",
    "        for n in list_n:\n",
    "            for d in list_d:\n",
    "                for s0_factor in list_s0_factor:\n",
    "                    for gt in list_gt:\n",
    "                    \n",
    "                        \n",
    "                        fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'nCon')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz.append(value[4])\n",
    "                        nvalid = len(tpr)\n",
    "                        assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "                            \n",
    "                        fdr2, tpr2, fpr2, shd2, nnz2 = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'nReg') ## nReg or nRegFlat\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr2.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr2.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr2.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd2.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz2.append(value[4])      \n",
    "                        nvalid2 = len(tpr2)\n",
    "                        assert nvalid2 == len(fdr2) == len(fpr2) == len(shd2) == len(nnz2)\n",
    "\n",
    "                        fdr3, tpr3, fpr3, shd3, nnz3 = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'nRegFlat') ## nReg or nRegFlat\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr3.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr3.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr3.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd3.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz3.append(value[4])      \n",
    "                        nvalid3 = len(tpr3)\n",
    "                        assert nvalid3 == len(fdr3) == len(fpr3) == len(shd3) == len(nnz3)\n",
    "                        \n",
    "\n",
    "                        # print(n, d, s0_factor, gt, should_std)                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr2), np.std(fdr2)))\n",
    "                        # t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr2), np.std(fdr2), nvalid2)                                                \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "                        # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr2), np.std(fpr2)))\n",
    "                        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr2), np.std(fpr2), nvalid2)                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "                        # t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "                        # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz2), np.std(nnz2), nvalid2)   \n",
    "                        # print(key[:-2], nvalid, nvalid2)\n",
    "                        # print()\n",
    "                        # print()\n",
    "                        # print(n, d, s0_factor, gt, should_std)  \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr3), np.std(fdr3)))\n",
    "                        t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr3), np.std(fdr3), nvalid3)                                                                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr3), np.std(tpr3)))\n",
    "                        # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr3), np.std(tpr3), nvalid3)                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr3), np.std(fpr3)))\n",
    "                        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr3), np.std(fpr3), nvalid3)                                                \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd3), np.std(shd3)))  \n",
    "                        t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd3), np.std(shd3), nvalid3)                    \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz3), np.std(nnz3)))   \n",
    "                        # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz3), np.std(nnz3), nvalid3)   \n",
    "                        # print(key[:-2], nvalid, nvalid3)\n",
    "                        # print()tpr\n",
    "                        # print()   \n",
    "                        \n",
    "                        row = [\n",
    "                            '(1-3)', \n",
    "                            str(should_std), n, d, s0_factor*d, gt, \n",
    "                            '{0}, {1}'.format(nvalid, nvalid3),\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr), np.std(fdr)),\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr3), np.std(fdr3)),\n",
    "                            p1, t1, s1,\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(shd), np.std(shd)),\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(shd3), np.std(shd3)),\n",
    "                            p2, t2, s2                            \n",
    "                        ]\n",
    "                        list_row.append(row)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list_row)\n",
    "writer = pd.ExcelWriter('datasets/result_2_nCon_nRegFlat.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
