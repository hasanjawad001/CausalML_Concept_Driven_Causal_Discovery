{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            s = 'Null rejected: more confident that mean(M1) < mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            s = 'Null rejected: more confident that mean(M1) > mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 1-pvalue\n",
    "        return (tstat, pvalue, '-----------------') ## return True\n",
    "    else:\n",
    "        s = 'Cannot reject null: no confidence which one is better'\n",
    "        print(s)\n",
    "        return (tstat, pvalue, s) ## return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "list_n = [200, 1000] ## [200, 1000]\n",
    "list_d = [10, 20] ## [10, 20]\n",
    "list_s0_factor = [1, 4] ## [1, 4]\n",
    "list_gt = ['ER', 'SF'] ## ['ER', 'SF']\n",
    "list_should_std = [False, True] ## [False, True]\n",
    "n_trials = 50 ## 10 or 50\n",
    "# list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "# list_n = [200] ## [200, 1000]\n",
    "# list_d = [10] ## [10, 20]\n",
    "# list_s0_factor = [1, 4] ## [1, 4]\n",
    "# list_gt = ['ER'] ## ['ER', 'SF']\n",
    "# list_should_std = [False] ## [False, True]\n",
    "# n_trials = 2 ## 10 or 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result = {}\n",
    "\n",
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        with open('datasets/d_result_' + str(n) + '_' + str(d) + '_' + str(s0_factor) + '_' + str(gt) + '_' + str(should_std) + '.pickle', 'rb') as handle:\n",
    "                            d_result_local = pickle.load(handle)\n",
    "                            d_result.update(d_result_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_result ## len := 4800 = 32 * 50 * 3 (nCon, nReg, nRegFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstat =  0.3449476608916843\n",
      "pvalue =  0.7312650905022416\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -29.391666388063808\n",
      "pvalue =  9.447494884125026e-48\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.6997672103372179\n",
      "pvalue =  0.4862777333956557\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -25.700586704009044\n",
      "pvalue =  3.797362737428271e-44\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.0363416182306047\n",
      "pvalue =  0.3040403205846354\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -18.035718304127688\n",
      "pvalue =  1.0387211125117865e-31\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.9486353543857947\n",
      "pvalue =  0.3464267409534134\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -20.49496593076025\n",
      "pvalue =  2.6482190471306183e-36\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.91169979494955\n",
      "pvalue =  0.004772971306988537\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -23.36302326246325\n",
      "pvalue =  5.083088461652889e-32\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  5.186028779839062\n",
      "pvalue =  1.8378349536685837e-06\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -18.789195815777838\n",
      "pvalue =  1.6423304863417182e-27\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.346775527544542\n",
      "pvalue =  0.022213542599056356\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -33.72922715570183\n",
      "pvalue =  2.9678161423094044e-54\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.4453886131186797\n",
      "pvalue =  0.15362381459827867\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -18.916675439149987\n",
      "pvalue =  4.137117838860189e-31\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.7961196639977897\n",
      "pvalue =  0.006596106934726692\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -19.1277296778826\n",
      "pvalue =  8.33289707922678e-34\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.797284602593806\n",
      "pvalue =  0.00632143079994277\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -19.119069599607535\n",
      "pvalue =  7.4596305784849535e-34\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.1484668290086548\n",
      "pvalue =  0.25513183832780134\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -14.900027728213937\n",
      "pvalue =  6.850902849177169e-27\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.4080785759734537\n",
      "pvalue =  0.6843706944402851\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -16.49996841906294\n",
      "pvalue =  3.921936284947057e-29\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.1203294402764556\n",
      "pvalue =  0.03717900048856943\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -29.417047675360003\n",
      "pvalue =  2.502104867803905e-41\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  2.309157082520058\n",
      "pvalue =  0.02453737024782458\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "tstat =  -28.715715655087777\n",
      "pvalue =  1.6689010359375694e-38\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.3806828512812332\n",
      "pvalue =  0.02011512907123494\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -25.06324204482938\n",
      "pvalue =  2.1140676993406652e-43\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.992510209724561\n",
      "pvalue =  0.05080876734482041\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -26.135706942551085\n",
      "pvalue =  3.4301258426688143e-43\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -5.977185012757941\n",
      "pvalue =  1.175578438329344e-07\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -30.904727413697024\n",
      "pvalue =  3.489185071877742e-48\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -7.359542284224517\n",
      "pvalue =  4.2479689602304974e-10\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -30.09016621518876\n",
      "pvalue =  8.558698266878514e-48\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -5.101051162191598\n",
      "pvalue =  3.674123314750389e-06\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -19.141279610511994\n",
      "pvalue =  3.696309027350041e-34\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.9113930376052455\n",
      "pvalue =  6.237511319240715e-06\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -19.99612155636342\n",
      "pvalue =  4.613032016138877e-35\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.3782526960339907\n",
      "pvalue =  0.019720760000009753\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -26.493095248343423\n",
      "pvalue =  2.752909307022238e-46\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -0.8629406098932707\n",
      "pvalue =  0.3909565571313781\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -27.978569569708114\n",
      "pvalue =  2.7557774566801137e-46\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.32919748337813\n",
      "pvalue =  5.349654230857575e-05\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -28.99372981396367\n",
      "pvalue =  2.0708781846241935e-49\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.267052296702538\n",
      "pvalue =  6.04670549763295e-05\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -20.267905487678973\n",
      "pvalue =  7.962188770364222e-37\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.406124992999165\n",
      "pvalue =  0.16428363745337576\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -14.069710325014501\n",
      "pvalue =  3.0887949479272966e-25\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  0.5457180650638512\n",
      "pvalue =  0.5868658764056035\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -13.255576334802619\n",
      "pvalue =  1.4252652130184802e-23\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -5.047377291873282\n",
      "pvalue =  2.9065624697331807e-06\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -11.040560082510698\n",
      "pvalue =  9.244947140046538e-19\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -3.233211805669304\n",
      "pvalue =  0.0018306223754746417\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -9.549574785276898\n",
      "pvalue =  1.5227077824516867e-15\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -1.593737460358709\n",
      "pvalue =  0.11518578515065289\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -16.55232262259204\n",
      "pvalue =  9.439042704323775e-29\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  1.284548881851504\n",
      "pvalue =  0.20237100195682825\n",
      "Cannot reject null: no confidence which one is better\n",
      "tstat =  -14.291027488378623\n",
      "pvalue =  1.3162402112971666e-25\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -4.7534260490084845\n",
      "pvalue =  8.78718925811804e-06\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -20.011701211762226\n",
      "pvalue =  2.2935387685604166e-36\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -2.214548857521618\n",
      "pvalue =  0.02989325156776867\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -12.45599430599358\n",
      "pvalue =  7.189510622379928e-22\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n"
     ]
    }
   ],
   "source": [
    "list_row = [\n",
    "    [\n",
    "        'dim_con',\n",
    "        'should_std', 'n', 'd', 's0', 'gt',\n",
    "        '# success (nCon, nReg)',\n",
    "        'fdr (nCon)', 'fdr (nReg)', 'pval', 'tstat', 'comment',\n",
    "        'shd (nCon)', 'shd (nReg)', 'pval', 'tstat', 'comment'        \n",
    "    ]\n",
    "]\n",
    "for dt, st in list_dt_st:\n",
    "    for should_std in list_should_std:    \n",
    "        for n in list_n:\n",
    "            for d in list_d:\n",
    "                for s0_factor in list_s0_factor:\n",
    "                    for gt in list_gt:\n",
    "                    \n",
    "                        \n",
    "                        fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'nCon')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz.append(value[4])\n",
    "                        nvalid = len(tpr)\n",
    "                        assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "                            \n",
    "                        fdr2, tpr2, fpr2, shd2, nnz2 = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'nReg') ## nReg or nRegFlat\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr2.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr2.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr2.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd2.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz2.append(value[4])      \n",
    "                        nvalid2 = len(tpr2)\n",
    "                        assert nvalid2 == len(fdr2) == len(fpr2) == len(shd2) == len(nnz2)\n",
    "\n",
    "                        fdr3, tpr3, fpr3, shd3, nnz3 = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'nRegFlat') ## nReg or nRegFlat\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr3.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr3.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr3.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd3.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz3.append(value[4])      \n",
    "                        nvalid3 = len(tpr3)\n",
    "                        assert nvalid3 == len(fdr3) == len(fpr3) == len(shd3) == len(nnz3)\n",
    "                        \n",
    "\n",
    "                        # print(n, d, s0_factor, gt, should_std)                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr2), np.std(fdr2)))\n",
    "#                         t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr2), np.std(fdr2), nvalid2)                                                \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "                        # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr2), np.std(fpr2)))\n",
    "                        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr2), np.std(fpr2), nvalid2)                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "#                         t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "                        # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz2), np.std(nnz2), nvalid2)   \n",
    "                        # print(key[:-2], nvalid, nvalid2)\n",
    "                        # print()\n",
    "                        # print()\n",
    "                        # print(n, d, s0_factor, gt, should_std)  \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr3), np.std(fdr3)))\n",
    "                        t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr3), np.std(fdr3), nvalid3)                                                                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr3), np.std(tpr3)))\n",
    "                        # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr3), np.std(tpr3), nvalid3)                        \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr3), np.std(fpr3)))\n",
    "                        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr3), np.std(fpr3), nvalid3)                                                \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd3), np.std(shd3)))  \n",
    "                        t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd3), np.std(shd3), nvalid3)                    \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz3), np.std(nnz3)))   \n",
    "                        # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz3), np.std(nnz3), nvalid3)   \n",
    "                        # print(key[:-2], nvalid, nvalid3)\n",
    "                        # print()tpr\n",
    "                        # print()   \n",
    "                        \n",
    "                        row = [\n",
    "                            '(1-3)', \n",
    "                            str(should_std), n, d, s0_factor*d, gt, \n",
    "                            '{0}, {1}'.format(nvalid, nvalid3),\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr), np.std(fdr)),\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr3), np.std(fdr3)),\n",
    "                            p1, t1, s1,\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(shd), np.std(shd)),\n",
    "                            \"{:0.2f} ± {:0.2f}\".format(np.mean(shd3), np.std(shd3)),\n",
    "                            p2, t2, s2                            \n",
    "                        ]\n",
    "                        list_row.append(row)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list_row)\n",
    "writer = pd.ExcelWriter('datasets/result_2_nCon_nRegFlat.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
