{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            print('Null rejected: more confident that mean(M1) < mean(M2)')\n",
    "            return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            print('Null rejected: more confident that mean(M1) > mean(M2)')\n",
    "            return 1-pvalue\n",
    "        return True\n",
    "    else:\n",
    "        print('Cannot reject null: no confidence which one is better')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "list_n = [200, 1000] ## [200, 1000]\n",
    "list_d = [20] ## [10, 20]\n",
    "list_s0_factor = [1, 4] ## [1, 4]\n",
    "list_gt = ['ER', 'SF'] ## ['ER', 'SF']\n",
    "list_should_std = [False, True] ## [False, True]\n",
    "n_trials = 50 ## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result = {}\n",
    "\n",
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        with open('datasets/d_result_' + str(n) + '_' + str(d) + '_' + str(s0_factor) + '_' + str(gt) + '_' + str(should_std) + '.pickle', 'rb') as handle:\n",
    "                            d_result_local = pickle.load(handle)\n",
    "                            d_result.update(d_result_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 20, 1, 'ER', False) ==> 0.17 ± 0.10 vs 0.17 ± 0.08\n",
      "tstat =  -0.17931690777662912\n",
      "pvalue =  0.8584155623643861\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 1, 'ER', False) ==> 155.59 ± 7.29 vs 175.27 ± 4.22\n",
      "tstat =  -12.08071952108361\n",
      "pvalue =  3.013736808251381e-15\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 20, 1, 'ER', False) ==> 154.85 ± 8.28 vs 176.88 ± 4.56\n",
      "(200, 20, 1, 'ER', False) 27 26\n",
      "\n",
      "\n",
      "(200, 20, 1, 'ER', True) ==> 0.47 ± 0.14 vs 0.49 ± 0.13\n",
      "tstat =  -0.8297291686595111\n",
      "pvalue =  0.4092076101058688\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 1, 'ER', True) ==> 151.33 ± 9.93 vs 139.03 ± 17.22\n",
      "tstat =  3.8712642011318334\n",
      "pvalue =  0.0002789067133925325\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 20, 1, 'ER', True) ==> 154.02 ± 10.68 vs 145.24 ± 19.78\n",
      "(200, 20, 1, 'ER', True) 43 38\n",
      "\n",
      "\n",
      "(200, 20, 1, 'SF', False) ==> 0.13 ± 0.05 vs 0.16 ± 0.06\n",
      "tstat =  -1.4530197704315686\n",
      "pvalue =  0.15231130296638018\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 1, 'SF', False) ==> 113.81 ± 15.85 vs 146.89 ± 18.49\n",
      "tstat =  -7.073844513459628\n",
      "pvalue =  3.890409591830091e-09\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 20, 1, 'SF', False) ==> 114.88 ± 15.43 vs 147.89 ± 18.33\n",
      "(200, 20, 1, 'SF', False) 26 28\n",
      "\n",
      "\n",
      "(200, 20, 1, 'SF', True) ==> 0.18 ± 0.11 vs 0.21 ± 0.10\n",
      "tstat =  -1.0566902147674355\n",
      "pvalue =  0.29418607542334063\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 1, 'SF', True) ==> 164.05 ± 8.82 vs 156.03 ± 9.31\n",
      "tstat =  3.8041174034325973\n",
      "pvalue =  0.0003045132876628441\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 20, 1, 'SF', True) ==> 161.15 ± 10.47 vs 155.15 ± 11.35\n",
      "(200, 20, 1, 'SF', True) 41 34\n",
      "\n",
      "\n",
      "(200, 20, 4, 'ER', False) ==> 0.36 ± 0.11 vs 0.43 ± 0.11\n",
      "tstat =  -2.706928021535909\n",
      "pvalue =  0.008762231996457327\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 20, 4, 'ER', False) ==> 136.09 ± 9.12 vs 144.62 ± 7.79\n",
      "tstat =  -4.024195011041526\n",
      "pvalue =  0.00016135824775143835\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 20, 4, 'ER', False) ==> 136.09 ± 16.38 vs 168.50 ± 7.47\n",
      "(200, 20, 4, 'ER', False) 32 32\n",
      "\n",
      "\n",
      "(200, 20, 4, 'ER', True) ==> 0.53 ± 0.08 vs 0.51 ± 0.08\n",
      "tstat =  1.3121143819731071\n",
      "pvalue =  0.19267680894316222\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 4, 'ER', True) ==> 113.14 ± 11.68 vs 103.74 ± 12.27\n",
      "tstat =  3.841656313448285\n",
      "pvalue =  0.00022282780981371485\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 20, 4, 'ER', True) ==> 134.12 ± 12.33 vs 126.21 ± 13.81\n",
      "(200, 20, 4, 'ER', True) 49 47\n",
      "\n",
      "\n",
      "(200, 20, 4, 'SF', False) ==> 0.26 ± 0.09 vs 0.27 ± 0.11\n",
      "tstat =  -0.5456781035984757\n",
      "pvalue =  0.5873894462674\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 4, 'SF', False) ==> 133.96 ± 9.72 vs 158.28 ± 7.75\n",
      "tstat =  -10.612296108150787\n",
      "pvalue =  1.432353899896298e-14\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(200, 20, 4, 'SF', False) ==> 144.04 ± 12.13 vs 171.12 ± 9.23\n",
      "(200, 20, 4, 'SF', False) 28 32\n",
      "\n",
      "\n",
      "(200, 20, 4, 'SF', True) ==> 0.28 ± 0.13 vs 0.30 ± 0.12\n",
      "tstat =  -0.8176629726360688\n",
      "pvalue =  0.41573330274635023\n",
      "Cannot reject null: no confidence which one is better\n",
      "(200, 20, 4, 'SF', True) ==> 138.58 ± 13.88 vs 124.86 ± 14.55\n",
      "tstat =  4.590042622712198\n",
      "pvalue =  1.4853772668983315e-05\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(200, 20, 4, 'SF', True) ==> 127.90 ± 13.79 vs 121.51 ± 19.88\n",
      "(200, 20, 4, 'SF', True) 48 43\n",
      "\n",
      "\n",
      "(1000, 20, 1, 'ER', False) ==> 0.19 ± 0.12 vs 0.16 ± 0.08\n",
      "tstat =  1.3019346212998595\n",
      "pvalue =  0.20122580233963\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 1, 'ER', False) ==> 166.92 ± 6.14 vs 165.32 ± 6.10\n",
      "tstat =  0.9917682273855102\n",
      "pvalue =  0.32618231841230516\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 1, 'ER', False) ==> 166.79 ± 6.82 vs 165.68 ± 6.96\n",
      "(1000, 20, 1, 'ER', False) 24 37\n",
      "\n",
      "\n",
      "(1000, 20, 1, 'ER', True) ==> 0.42 ± 0.13 vs 0.45 ± 0.12\n",
      "tstat =  -1.0088772550737193\n",
      "pvalue =  0.31582432789994946\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 1, 'ER', True) ==> 84.02 ± 19.86 vs 46.62 ± 13.40\n",
      "tstat =  10.579400222694774\n",
      "pvalue =  4.7432685856652467e-17\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 20, 1, 'ER', True) ==> 83.73 ± 19.39 vs 50.21 ± 13.83\n",
      "(1000, 20, 1, 'ER', True) 48 42\n",
      "\n",
      "\n",
      "(1000, 20, 1, 'SF', False) ==> 0.12 ± 0.05 vs 0.11 ± 0.07\n",
      "tstat =  0.3286475894585009\n",
      "pvalue =  0.745220300045845\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 1, 'SF', False) ==> 118.55 ± 20.44 vs 150.04 ± 14.53\n",
      "tstat =  -4.6535133308922205\n",
      "pvalue =  0.00035206885506990765\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 20, 1, 'SF', False) ==> 117.55 ± 19.77 vs 148.74 ± 14.45\n",
      "(1000, 20, 1, 'SF', False) 11 27\n",
      "\n",
      "\n",
      "(1000, 20, 1, 'SF', True) ==> 0.12 ± 0.08 vs 0.13 ± 0.11\n",
      "tstat =  -0.580340275883483\n",
      "pvalue =  0.5631925630228022\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 1, 'SF', True) ==> 119.83 ± 20.18 vs 69.25 ± 15.63\n",
      "tstat =  13.729205148073566\n",
      "pvalue =  1.2119139667731678e-23\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 20, 1, 'SF', True) ==> 111.15 ± 19.69 vs 64.27 ± 15.82\n",
      "(1000, 20, 1, 'SF', True) 48 48\n",
      "\n",
      "\n",
      "(1000, 20, 4, 'ER', False) ==> 0.40 ± 0.12 vs 0.37 ± 0.10\n",
      "tstat =  1.3171852019657968\n",
      "pvalue =  0.19187603079256985\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 4, 'ER', False) ==> 133.90 ± 11.22 vs 124.76 ± 10.78\n",
      "tstat =  3.6463539219523096\n",
      "pvalue =  0.0004886155578258574\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 20, 4, 'ER', False) ==> 142.28 ± 13.62 vs 129.70 ± 15.72\n",
      "(1000, 20, 4, 'ER', False) 40 37\n",
      "\n",
      "\n",
      "(1000, 20, 4, 'ER', True) ==> 0.48 ± 0.08 vs 0.52 ± 0.08\n",
      "tstat =  -2.2019399655563854\n",
      "pvalue =  0.03017650592030361\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 20, 4, 'ER', True) ==> 70.21 ± 9.88 vs 75.76 ± 10.16\n",
      "tstat =  -2.6851877303365246\n",
      "pvalue =  0.008606053970427097\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 20, 4, 'ER', True) ==> 73.90 ± 13.53 vs 95.50 ± 11.84\n",
      "(1000, 20, 4, 'ER', True) 48 46\n",
      "\n",
      "\n",
      "(1000, 20, 4, 'SF', False) ==> 0.22 ± 0.14 vs 0.20 ± 0.11\n",
      "tstat =  0.3218124626363761\n",
      "pvalue =  0.7496319608701826\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 4, 'SF', False) ==> 153.37 ± 10.02 vs 158.03 ± 6.46\n",
      "tstat =  -1.8050884444844477\n",
      "pvalue =  0.08200476745853355\n",
      "Cannot reject null: no confidence which one is better\n",
      "(1000, 20, 4, 'SF', False) ==> 151.68 ± 20.11 vs 156.50 ± 9.08\n",
      "(1000, 20, 4, 'SF', False) 19 30\n",
      "\n",
      "\n",
      "(1000, 20, 4, 'SF', True) ==> 0.09 ± 0.07 vs 0.21 ± 0.12\n",
      "tstat =  -5.960553994957832\n",
      "pvalue =  6.08447493115696e-08\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "(1000, 20, 4, 'SF', True) ==> 88.38 ± 15.34 vs 75.71 ± 11.50\n",
      "tstat =  4.591619513908765\n",
      "pvalue =  1.4705072327555194e-05\n",
      "Null rejected: more confident that mean(M1) > mean(M2)\n",
      "(1000, 20, 4, 'SF', True) ==> 38.17 ± 17.69 vs 51.92 ± 14.25\n",
      "(1000, 20, 4, 'SF', True) 48 49\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        \n",
    "                        fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'X')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz.append(value[4])\n",
    "                        nvalid = len(tpr)\n",
    "                        assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "                            \n",
    "                        fdr2, tpr2, fpr2, shd2, nnz2 = [], [], [], [], []\n",
    "                        for tn in range(n_trials):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'X_fake')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr2.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr2.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr2.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd2.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz2.append(value[4])      \n",
    "                        nvalid2 = len(tpr2)\n",
    "                        assert nvalid2 == len(fdr2) == len(fpr2) == len(shd2) == len(nnz2)\n",
    "                                \n",
    "                          \n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr2), np.std(fdr2)))\n",
    "                        # which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr2), np.std(fdr2), nvalid2)                                                \n",
    "                        print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "                        which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "                        # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr2), np.std(fpr2)))\n",
    "                        # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr2), np.std(fpr2), nvalid2)                        \n",
    "                        print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "                        which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "                        print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "                        print(key[:-2], nvalid, nvalid2)\n",
    "                        print()\n",
    "                        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
