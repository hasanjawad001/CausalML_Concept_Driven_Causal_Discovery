{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            s = 'Null rejected: more confident that mean(M1) < mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            s = 'Null rejected: more confident that mean(M1) > mean(M2)'\n",
    "            print(s)\n",
    "            return (tstat, pvalue, s) ## return 1-pvalue\n",
    "        return (tstat, pvalue, '-----------------') ## return True\n",
    "    else:\n",
    "        s = 'Cannot reject null: no confidence which one is better'\n",
    "        print(s)\n",
    "        return (tstat, pvalue, s) ## return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_should_std = [False, True] ## [False, True]\n",
    "n_trials = 50 ## 10 or 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result = {}\n",
    "\n",
    "for should_std in list_should_std:\n",
    "    with open('datasets/d_result_' + str(should_std) + '.pickle', 'rb') as handle:\n",
    "        d_result_local = pickle.load(handle)\n",
    "        d_result.update(d_result_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d_result ## len := 4800 = 32 * 50 * 3 (nCon, nReg, nRegFlat)\n",
    "len(d_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstat =  -21.97561232949915\n",
      "pvalue =  1.7885585407569135e-39\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -25.999634534986107\n",
      "pvalue =  8.47294469384425e-31\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -21.163710838744823\n",
      "pvalue =  3.04931357726367e-27\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n",
      "tstat =  -43.294783620018435\n",
      "pvalue =  1.3493301805805456e-41\n",
      "Null rejected: more confident that mean(M1) < mean(M2)\n"
     ]
    }
   ],
   "source": [
    "list_row = [\n",
    "    [\n",
    "        'should_std', '# success (nCon, nReg)',\n",
    "        'fdr (nCon)', 'fdr (nReg)', 'pval', 'tstat', 'comment',\n",
    "        'shd (nCon)', 'shd (nReg)', 'pval', 'tstat', 'comment'        \n",
    "    ]\n",
    "]\n",
    "for should_std in list_should_std:    \n",
    "    fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "    for tn in range(n_trials):\n",
    "        key = (should_std, tn, 'nCon')\n",
    "        value = d_result[key]\n",
    "        if value[0] != '-':\n",
    "            fdr.append(value[0])\n",
    "        if value[1] != '-':\n",
    "            tpr.append(value[1])\n",
    "        if value[2] != '-':\n",
    "            fpr.append(value[2])\n",
    "        if value[3] != '-':\n",
    "            shd.append(value[3])\n",
    "        if value[4] != '-':\n",
    "            nnz.append(value[4])\n",
    "    nvalid = len(tpr)\n",
    "    assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "\n",
    "    fdr3, tpr3, fpr3, shd3, nnz3 = [], [], [], [], []\n",
    "    for tn in range(n_trials):\n",
    "        key = (should_std, tn, 'nRegFlat') ## nReg or nRegFlat\n",
    "        value = d_result[key]\n",
    "        if value[0] != '-':\n",
    "            fdr3.append(value[0])\n",
    "        if value[1] != '-':\n",
    "            tpr3.append(value[1])\n",
    "        if value[2] != '-':\n",
    "            fpr3.append(value[2])\n",
    "        if value[3] != '-':\n",
    "            shd3.append(value[3])\n",
    "        if value[4] != '-':\n",
    "            nnz3.append(value[4])      \n",
    "    nvalid3 = len(tpr3)\n",
    "    assert nvalid3 == len(fdr3) == len(fpr3) == len(shd3) == len(nnz3)\n",
    "\n",
    "\n",
    "    # print(n, d, s0_factor, gt, should_std)                        \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr2), np.std(fdr2)))\n",
    "#     t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr2), np.std(fdr2), nvalid2)                                                \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "    # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr2), np.std(fpr2)))\n",
    "    # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr2), np.std(fpr2), nvalid2)                        \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "#     t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "    # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz2), np.std(nnz2), nvalid2)   \n",
    "    # print(key[:-2], nvalid, nvalid2)\n",
    "    # print()\n",
    "    # print()\n",
    "    # print(n, d, s0_factor, gt, should_std)  \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fdr), np.std(fdr), np.mean(fdr3), np.std(fdr3)))\n",
    "    t1, p1, s1 = which_is_better(np.mean(fdr), np.std(fdr), nvalid, np.mean(fdr3), np.std(fdr3), nvalid3)                                                                        \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr3), np.std(tpr3)))\n",
    "    # which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr3), np.std(tpr3), nvalid3)                        \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(fpr), np.std(fpr), np.mean(fpr3), np.std(fpr3)))\n",
    "    # which_is_better(np.mean(fpr), np.std(fpr), nvalid, np.mean(fpr3), np.std(fpr3), nvalid3)                                                \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd3), np.std(shd3)))  \n",
    "    t2, p2, s2 = which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd3), np.std(shd3), nvalid3)                    \n",
    "    # print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz3), np.std(nnz3)))   \n",
    "    # which_is_better(np.mean(nnz), np.std(nnz), nvalid, np.mean(nnz3), np.std(nnz3), nvalid3)   \n",
    "    # print(key[:-2], nvalid, nvalid3)\n",
    "    # print()tpr\n",
    "    # print()   \n",
    "\n",
    "    row = [\n",
    "        str(should_std), '{0}, {1}'.format(nvalid, nvalid3),\n",
    "        \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr), np.std(fdr)),\n",
    "        \"{:0.2f} ± {:0.2f}\".format(np.mean(fdr3), np.std(fdr3)),\n",
    "        p1, t1, s1,\n",
    "        \"{:0.2f} ± {:0.2f}\".format(np.mean(shd), np.std(shd)),\n",
    "        \"{:0.2f} ± {:0.2f}\".format(np.mean(shd3), np.std(shd3)),\n",
    "        p2, t2, s2                            \n",
    "    ]\n",
    "    list_row.append(row)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list_row)\n",
    "writer = pd.ExcelWriter('datasets/result_1_nCon_nRegFlat.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>should_std</td>\n",
       "      <td># success (nCon, nReg)</td>\n",
       "      <td>fdr (nCon)</td>\n",
       "      <td>fdr (nReg)</td>\n",
       "      <td>pval</td>\n",
       "      <td>tstat</td>\n",
       "      <td>comment</td>\n",
       "      <td>shd (nCon)</td>\n",
       "      <td>shd (nReg)</td>\n",
       "      <td>pval</td>\n",
       "      <td>tstat</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>50, 50</td>\n",
       "      <td>0.33 ± 0.11</td>\n",
       "      <td>0.77 ± 0.10</td>\n",
       "      <td>1.78856e-39</td>\n",
       "      <td>-21.9756</td>\n",
       "      <td>Null rejected: more confident that mean(M1) &lt; ...</td>\n",
       "      <td>5.06 ± 0.24</td>\n",
       "      <td>12.90 ± 2.12</td>\n",
       "      <td>8.47294e-31</td>\n",
       "      <td>-25.9996</td>\n",
       "      <td>Null rejected: more confident that mean(M1) &lt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>50, 50</td>\n",
       "      <td>0.75 ± 0.01</td>\n",
       "      <td>0.87 ± 0.04</td>\n",
       "      <td>3.04931e-27</td>\n",
       "      <td>-21.1637</td>\n",
       "      <td>Null rejected: more confident that mean(M1) &lt; ...</td>\n",
       "      <td>9.02 ± 0.14</td>\n",
       "      <td>16.00 ± 1.13</td>\n",
       "      <td>1.34933e-41</td>\n",
       "      <td>-43.2948</td>\n",
       "      <td>Null rejected: more confident that mean(M1) &lt; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                       1            2            3            4   \\\n",
       "0  should_std  # success (nCon, nReg)   fdr (nCon)   fdr (nReg)         pval   \n",
       "1       False                  50, 50  0.33 ± 0.11  0.77 ± 0.10  1.78856e-39   \n",
       "2        True                  50, 50  0.75 ± 0.01  0.87 ± 0.04  3.04931e-27   \n",
       "\n",
       "        5                                                  6            7   \\\n",
       "0    tstat                                            comment   shd (nCon)   \n",
       "1 -21.9756  Null rejected: more confident that mean(M1) < ...  5.06 ± 0.24   \n",
       "2 -21.1637  Null rejected: more confident that mean(M1) < ...  9.02 ± 0.14   \n",
       "\n",
       "             8            9        10  \\\n",
       "0    shd (nReg)         pval    tstat   \n",
       "1  12.90 ± 2.12  8.47294e-31 -25.9996   \n",
       "2  16.00 ± 1.13  1.34933e-41 -43.2948   \n",
       "\n",
       "                                                  11  \n",
       "0                                            comment  \n",
       "1  Null rejected: more confident that mean(M1) < ...  \n",
       "2  Null rejected: more confident that mean(M1) < ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('datasets/result_1_nCon_nRegFlat.xlsx').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
