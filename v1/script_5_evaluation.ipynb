{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "## stats.ttest_ind, stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_is_better(mean1, std1, nobs1, mean2, std2, nobs2, alpha_one_tail=0.025):\n",
    "    # Test whether mean(M1) > mean(M2) using Welch's t-test\n",
    "    # at default alpha = 0.025 significance level for the one tail test\n",
    "    #\n",
    "    # M1 - relevant\n",
    "    # M2 - irrelevant\n",
    "    #\n",
    "    # Note that stats.ttest_ind return the two-tailed p-value\n",
    "    #\n",
    "    # Null hypothesis: mean(M1) <= mean(M2)\n",
    "    # Alternative: mean(M1) > mean(M2) \n",
    "    #\n",
    "    # REJECT if pvalue/2 < alpha\n",
    "    \n",
    "    # tstat, pvalue = stats.ttest_ind(M1_values, M2_values, equal_var = False)\n",
    "    tstat, pvalue = stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var = False)    \n",
    "    print('tstat = ', tstat)\n",
    "    print('pvalue = ', pvalue)\n",
    "    if pvalue/2 < alpha_one_tail:\n",
    "        if tstat < 0.0:\n",
    "            print('Null rejected: more confident that mean(M1) < mean(M2)')\n",
    "            return 0\n",
    "        else:\n",
    "            # you want to be here\n",
    "            print('Null rejected: more confident that mean(M1) > mean(M2)')\n",
    "            return 1-pvalue\n",
    "        return True\n",
    "    else:\n",
    "        print('Cannot reject null: no confidence which one is better')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dt_st = [('nonlinear', 'mlp')] ## [('nonlinear', 'mlp'), ('linear', 'mlp')]\n",
    "list_n = [200, 1000] ## [200, 1000]\n",
    "list_d = [5, 10] ## [10, 20]\n",
    "list_s0_factor = [1, 2] ## [1, 4]\n",
    "list_gt = ['ER', 'SF'] ## ['ER', 'SF']\n",
    "list_should_std = [False, True] ## [False, True]\n",
    "n_trials = 10 ## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result = {}\n",
    "\n",
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        with open('datasets/d_result_' + str(n) + '_' + str(d) + '_' + str(s0_factor) + '_' + str(gt) + '_' + str(should_std) + '.pickle', 'rb') as handle:\n",
    "                            d_result_local = pickle.load(handle)\n",
    "                            d_result.update(d_result_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt, st in list_dt_st:\n",
    "    for n in list_n:\n",
    "        for d in list_d:\n",
    "            for s0_factor in list_s0_factor:\n",
    "                for gt in list_gt:\n",
    "                    for should_std in list_should_std:\n",
    "                        \n",
    "                        fdr, tpr, fpr, shd, nnz = [], [], [], [], []\n",
    "                        for tn in range(10):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'X')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz.append(value[4])\n",
    "                        nvalid = len(tpr)\n",
    "                        assert nvalid == len(fdr) == len(fpr) == len(shd) == len(nnz)\n",
    "                            \n",
    "                        fdr2, tpr2, fpr2, shd2, nnz2 = [], [], [], [], []\n",
    "                        for tn in range(10):\n",
    "                            key = (n, d, s0_factor, gt, should_std, tn, 'X_fake')\n",
    "                            value = d_result[key]\n",
    "                            if value[0] != '-':\n",
    "                                fdr2.append(value[0])\n",
    "                            if value[1] != '-':\n",
    "                                tpr2.append(value[1])\n",
    "                            if value[2] != '-':\n",
    "                                fpr2.append(value[2])\n",
    "                            if value[3] != '-':\n",
    "                                shd2.append(value[3])\n",
    "                            if value[4] != '-':\n",
    "                                nnz2.append(value[4])      \n",
    "                        nvalid2 = len(tpr2)\n",
    "                        assert nvalid2 == len(fdr2) == len(fpr2) == len(shd2) == len(nnz2)\n",
    "                                \n",
    "                                \n",
    "#                         print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(tpr), np.std(tpr), np.mean(tpr2), np.std(tpr2)))\n",
    "#                         which_is_better(np.mean(tpr), np.std(tpr), nvalid, np.mean(tpr2), np.std(tpr2), nvalid2)\n",
    "#                         print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(shd), np.std(shd), np.mean(shd2), np.std(shd2)))  \n",
    "#                         which_is_better(np.mean(shd), np.std(shd), nvalid, np.mean(shd2), np.std(shd2), nvalid2)                    \n",
    "#                         print(\"{} ==> {:0.2f} ± {:0.2f} vs {:0.2f} ± {:0.2f}\".format(key[:-2], np.mean(nnz), np.std(nnz), np.mean(nnz2), np.std(nnz2)))   \n",
    "#                         print(key[:-2], nvalid, nvalid2)\n",
    "#                         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
